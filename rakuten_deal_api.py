import requests
import pandas as pd
import time
import math
from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.chrome.options import Options

# æ¥½å¤©APIã®è¨­å®š
RAKUTEN_APP_ID = "1031766687290699191"
RAKUTEN_API_URL = "https://app.rakuten.co.jp/services/api/IchibaItem/Search/20220601"
MAX_ITEMS = 20  # å–å¾—ã™ã‚‹æœ€å¤§ä»¶æ•°
HITS_PER_PAGE = 10  # 1å›ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã§å–å¾—ã™ã‚‹ä»¶æ•°ï¼ˆæœ€å¤§30ï¼‰
KEY_WORDS = "ã‚·ãƒ£ãƒ¼ãƒ— æ—¥ç«‹"  # ORæ¤œç´¢ï¼ˆè¤‡æ•°ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å¯¾å¿œï¼‰

# ãƒ˜ãƒƒãƒ€ãƒ¼è¨­å®š
HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36"
}

# Seleniumã®è¨­å®š
options = Options()
options.add_argument("--headless")  # ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰ï¼ˆç”»é¢ã‚’é–‹ã‹ãšã«å‹•ä½œï¼‰
options.add_argument("--no-sandbox")
options.add_argument("--disable-dev-shm-usage")

# WebDriverã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
service = Service(ChromeDriverManager().install())
driver = webdriver.Chrome(service=service, options=options)

# æ¥½å¤©APIã‹ã‚‰å•†å“ã‚’å–å¾—ã™ã‚‹é–¢æ•°
def get_rakuten_deal_items():
    items = []
    print(f"ğŸ“¦ æ¥½å¤©APIã‹ã‚‰å•†å“ã‚’å–å¾—ä¸­...")

    total_pages = math.ceil(MAX_ITEMS / HITS_PER_PAGE)  # åˆ‡ã‚Šä¸Šã’è¨ˆç®—ã§ãƒšãƒ¼ã‚¸æ•°ã‚’æ±‚ã‚ã‚‹

    for page in range(1, total_pages + 1):  # 1ãƒšãƒ¼ã‚¸ç›®ã‹ã‚‰é †ã«å–å¾—
        print(f"ğŸ“„ ãƒšãƒ¼ã‚¸ {page} ã‚’å–å¾—ä¸­...")

        params = {
            "format": "json",
            "applicationId": RAKUTEN_APP_ID,
            "hits": HITS_PER_PAGE,  # 1ãƒšãƒ¼ã‚¸ã‚ãŸã‚Šã®å–å¾—ä»¶æ•°
            "sort": "standard",  
            "page": page,  # ãƒšãƒ¼ã‚¸ç•ªå·ã‚’è¨­å®š
            "keyword": KEY_WORDS,  
            "itemCondition": 1,  
            "orFlag": 1, # 0:ANDæ¤œç´¢ 1:ORæ¤œç´¢
            "shopCode": "superdeal",
            "availability": 1,
            "field": 1, # 0ï¼šå¤šãã®æ¤œç´¢çµæœ 1ï¼šé™å®šã•ã‚ŒãŸçµæœ
        }

        response = requests.get(RAKUTEN_API_URL, params=params)
        if response.status_code != 200:
            print(f"âŒ APIãƒªã‚¯ã‚¨ã‚¹ãƒˆå¤±æ•—: {response.status_code}")
            print("ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸:", response.text)
            continue

        data = response.json()
        if not data.get("Items"):
            print("âš  ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™ã€‚")
            break

        # å•†å“æƒ…å ±ã‚’ãƒªã‚¹ãƒˆã«è¿½åŠ 
        for item in data["Items"]:
            item_info = item["Item"]
            item_name = item_info.get("itemName", "N/A")

            items.append({
                "itemName": item_name,
                "catchcopy": item_info.get("catchcopy", "N/A"),
                "itemCode": item_info.get("itemCode", "N/A"),
                "itemPrice": item_info.get("itemPrice", "N/A"),
                "itemUrl": item_info.get("itemUrl", "N/A"),
                "shop_name": item_info.get("shopName", "N/A"),
                "availability": item_info.get("availability", "N/A"),
                "taxFlag": item_info.get("taxFlag", "N/A"),
                "postageFlag": item_info.get("postageFlag", "N/A"),
                "pointRate": item_info.get("pointRate", "N/A"),
                "pointRateStartTime": item_info.get("pointRateStartTime", "N/A"),
                "pointRateEndTime": item_info.get("pointRateEndTime", "N/A"),
                "genreId": item_info.get("genreId", "N/A"),
            })

    return items

# æ¥½å¤©ã®å•†å“ãƒšãƒ¼ã‚¸ã‹ã‚‰ãƒã‚¤ãƒ³ãƒˆé‚„å…ƒæƒ…å ±ã®`ul`è¦ç´ ã‚’å–å¾—ã™ã‚‹é–¢æ•°
def get_point_summary_block(itemUrl):
    print(f"ğŸ” {itemUrl} ã®ãƒã‚¤ãƒ³ãƒˆæƒ…å ±ã‚’å–å¾—ä¸­...")
    try:
        driver.get(itemUrl)
        time.sleep(1)  # JavaScriptãŒå®Ÿè¡Œã•ã‚Œã‚‹ã®ã‚’å¾…ã¤

        soup = BeautifulSoup(driver.page_source, "html.parser")

        # `ul.point-summary` ã®ãƒ–ãƒ­ãƒƒã‚¯å…¨ä½“ã‚’å–å¾—
        point_element = soup.select_one("ul[class*=point-summary]")
        if point_element:
            return point_element.text.strip()  # HTMLå…¨ä½“ã§ã¯ãªãã€ãƒ†ã‚­ã‚¹ãƒˆã®ã¿å–å¾—

        return "N/A"

    except Exception as e:
        print(f"âš  ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å¤±æ•—: {itemUrl} - {str(e)}")
        return "N/A"

# ãƒ¡ã‚¤ãƒ³å‡¦ç†
def main():
    rakuten_items = get_rakuten_deal_items()
    if not rakuten_items:
        print("âŒ å•†å“ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
        return
    
    df = pd.DataFrame(rakuten_items)

    # å„å•†å“ã®ãƒã‚¤ãƒ³ãƒˆé‚„å…ƒæƒ…å ±ã®ãƒ–ãƒ­ãƒƒã‚¯ã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã—ã¦è¿½åŠ 
    print("ğŸ” å„å•†å“ã®ãƒã‚¤ãƒ³ãƒˆé‚„å…ƒæƒ…å ±ãƒ–ãƒ­ãƒƒã‚¯ã‚’å–å¾—ä¸­...")
    df["point_summary_block"] = df["itemUrl"].apply(get_point_summary_block)

    # CSVã«ä¿å­˜
    output_path = r"C:\Users\masa_\python\rakuten_dealshop_items.csv"
    df.to_csv(output_path, index=False, encoding="utf-8-sig")
    print(f"âœ… ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {output_path}")

    # å–å¾—ã—ãŸãƒ‡ãƒ¼ã‚¿ã®ä¸Šä½5ä»¶ã‚’è¡¨ç¤º
    print("\nğŸ“Š å–å¾—ã—ãŸãƒ‡ãƒ¼ã‚¿ï¼ˆä¸Šä½5ä»¶ï¼‰:")
    print(df.head())

if __name__ == "__main__":
    main()

    # WebDriverã‚’é–‰ã˜ã‚‹
    driver.quit()
